{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# from segment_anything import SamPredictor\n",
    "import supervision as sv\n",
    "import supervision.draw.color as sv_color\n",
    "import torch\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "from skimage import io\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import image_path\n",
    "image_path = pathlib.Path(\"../../data/0.raw_images/\")\n",
    "# max_projection paths\n",
    "max_projection_path = pathlib.Path(\"../../data/1.maximum_projections/\")\n",
    "# output mask path\n",
    "mask_path = pathlib.Path(\"../../data/2.masks/\")\n",
    "# sqlite path\n",
    "sqlite_path = pathlib.Path(\"../../data/3.sqlite_output/\")\n",
    "# models path\n",
    "models_path = pathlib.Path(\"../../data/models/\")\n",
    "\n",
    "# create directories if they don't exist\n",
    "max_projection_path.mkdir(parents=True, exist_ok=True)\n",
    "mask_path.mkdir(parents=True, exist_ok=True)\n",
    "sqlite_path.mkdir(parents=True, exist_ok=True)\n",
    "models_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of all the images in the image_path directory of max projection images\n",
    "image_list = list(max_projection_path.glob(\"*.tif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the SAM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "# # download the model if it doesn't exist\n",
    "# if not pathlib.Path(\"../../models/vit_h.pth\").exists():\n",
    "#     !wget\n",
    "\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "CHECKPOINT_PATH = \"../../data/models/vit_h.pth\"\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over the files and segment masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.62s/it]\n"
     ]
    }
   ],
   "source": [
    "for image_path in tqdm(image_list):\n",
    "    image_path = str(image_path)\n",
    "    # read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # define the file basename\n",
    "    image_path = pathlib.Path(image_path)\n",
    "    file_basename = image_path.stem\n",
    "    # convert the image to RGB format\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # convert to unit8 format\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    # invert the image\n",
    "    image = cv2.bitwise_not(image)\n",
    "    # # segment the image\n",
    "    masks = mask_generator.generate(image)\n",
    "\n",
    "    # Sort the masks by area\n",
    "    masks = sorted(masks, key=(lambda x: x[\"area\"]), reverse=True)\n",
    "    # remove the background mask\n",
    "    # a background mask is created by default hence the segment everything model\n",
    "    masks = masks[1:]\n",
    "\n",
    "    # annotate the masks\n",
    "    mask_annotator = sv.MaskAnnotator(\n",
    "        color=sv_color.Color(r=255, g=0, b=255), color_lookup=sv.ColorLookup.INDEX\n",
    "    )\n",
    "    # detect the masks\n",
    "    detections = sv.Detections.from_sam(sam_result=masks)\n",
    "\n",
    "    # annotate the image\n",
    "    annotated_image = mask_annotator.annotate(scene=image.copy(), detections=detections)\n",
    "\n",
    "    # Convert to uint8 format for conversion to grayscale\n",
    "    mask_image = (annotated_image * 255).astype(np.uint8)\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n",
    "    # threshold the image to create a binary mask image\n",
    "    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    # invert the image such that the background is black and the signal are white\n",
    "    gray = cv2.bitwise_not(gray)\n",
    "    # write the image to mask with basename\n",
    "    outpath = str(pathlib.Path(mask_path, file_basename + \".png\"))\n",
    "    cv2.imwrite(outpath, gray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "op_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
